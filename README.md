Real-Time Organ Detection for Laparoscopic Surgery using YOLOv11n

A lightweight, high-performance computer vision system designed to detect organs in live laparoscopic surgery using YOLOv11n.
This project explores how real-time AI can support surgeons by enhancing intra-operative visibility and reducing cognitive load during minimally invasive procedures.

ğŸš€ Overview

This repository contains the full pipeline for training, validating, and deploying an organ detection model optimized for real-time surgical environments.
The model is trained on laparoscopic datasets and tuned to handle challenges such as:

Occlusions

Surgical instrument interference

Low-light/variable illumination

Complex tissue textures

The goal is to demonstrate how modern object detection architectures can be adapted for medical AI and operating-room assistance systems.

ğŸ§  Model Architecture

The project uses YOLOv11n due to its balance of:

High inference speed

Lightweight deployment footprint

Strong accuracy for small and medium objects

Custom modifications were applied to improve detection stability during rapid camera motion and high-variance frames.

ğŸ—ï¸ Project Structure
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Original dataset
â”‚   â”œâ”€â”€ processed/            # Preprocessed images + annotations
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ training.ipynb        # Model training workflow
â”‚   â”œâ”€â”€ evaluation.ipynb      # Evaluation & visualization
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ yolov11n.pt           # Final trained weights
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py            # Dataloader and preprocessing
â”‚   â”œâ”€â”€ train.py              # Training pipeline
â”‚   â”œâ”€â”€ infer.py              # Real-time inference script
â”‚   â”œâ”€â”€ utils.py              # Helper functions
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ metrics.json          # Precision, recall, mAP, FPS
â”‚   â”œâ”€â”€ sample_outputs/       # Annotated output frames
â””â”€â”€ README.md

ğŸ§ª Training Pipeline

The training workflow includes:

Dataset annotation standardization

Image augmentation (blurs, rotations, low-light simulation)

Hyperparameter tuning

Validation and mAP analysis

FPS and latency testing for real-time use

You can run the official pipeline using:

python train.py --data data.yaml --weights yolov11n.pt --epochs 50

ğŸ“Š Performance Summary
Metric	Value
Precision	XX%
Recall	XX%
mAP50	XX%
Real-time FPS	XX (on Colab T4)

Replace XX with your actual metrics.

ğŸ¯ Use Cases

This system is designed for research and prototyping in:

AI-assisted surgery

Laparoscopic guidance systems

Real-time medical imaging

Surgical tool/organ detection pipelines

Healthcare robotics

â–¶ï¸ Real-Time Inference

Run live detection:

python infer.py --weights models/yolov11n.pt --source <video_path or webcam_id>


Output frames will be saved in results/sample_outputs/.

ğŸ› ï¸ Tech Stack

Python

PyTorch

YOLOv11n

OpenCV

NumPy

Jupyter/Colab

ğŸ“ Dataset

Due to medical imaging restrictions, datasets are not included in the repository.
Please refer to publicly available laparoscopic surgery datasets or use your own annotated dataset.

ğŸ¤ Contributing

Contributions are welcome.
Feel free to open issues, submit pull requests, or suggest improvements.

ğŸ“œ License

This project is for research and educational purposes.
Not intended for clinical use without regulatory approval.
